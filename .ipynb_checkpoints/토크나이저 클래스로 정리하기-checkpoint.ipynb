{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f085b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tokenizers import Tokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69edf6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserTokenizers:\n",
    "    \"\"\"class info : 사용자의 필요에 맞게 다양한 토크나이저를 적용하는 모듈\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        self.bpe_tokenizer_pretrained= Tokenizer.from_file(\"./mode_data/bpe_tokenizer.json\")\n",
    "        self.wp_tokenizer_pretrained= Tokenizer.from_file(\"./mode_data/wp_tokenizer.josn\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def whitespaceToken( data: str)-> list:\n",
    "        \"\"\"\n",
    "        funcinfo whitespaceToken: 공백문자로 데이터를 나누는 토큰화\n",
    "        param data : 토큰화할 문자 데이터\n",
    "        return token_rs: 토큰 결과 \n",
    "        \"\"\"\n",
    "        token_rs= data.split(' ')\n",
    "        return token_rs\n",
    "    @staticmethod\n",
    "    def regexsplitToken(data: str, pat: str = '[\\.\\,!?\\n]')-> list:\n",
    "        \"\"\"\n",
    "        funcinfo regexsplitToken: 정규표현식의 패턴을 기준으로 데이터를 토큰화\n",
    "        param data : 토큰화할 문자 데이터\n",
    "        param pat : 토큰화할 정규식\n",
    "        return token_rs: 토큰 결과\n",
    "        \"\"\"\n",
    "        re_rs= re.split(pat, data, maxsplit=0)\n",
    "        token_rs=[rs_unit.strip()for rs_unit in re_rs if len(rs_unit.strip())>1]\n",
    "        return token_rs\n",
    "    @staticmethod\n",
    "    def regexselectToken(data: str, pat: str='[\\w]+') -> list:\n",
    "        \"\"\"\n",
    "        funcinfo regexselectToken: 정규표현식의 패턴을 선택하여 토큰화\n",
    "        param data : 토큰화할 문자 데이터\n",
    "        param pat : 토큰화할 정규식\n",
    "        return token_rs: 토큰 결과\n",
    "        \"\"\"\n",
    "        token_rs = RegexpTokenizer(pat).tokenize(data)\n",
    "        return token_rs\n",
    "    \n",
    "    def BPETokenizer(self, data : str) -> list :\n",
    "        \"\"\"\n",
    "        funcinfo BPETokenizer: char bpe로 훈련된 모델로 토큰화\n",
    "        param data : 토큰화할 문자 데이터\n",
    "        return token_rs: 토큰 결과\n",
    "        \"\"\"\n",
    "        token_rs = self.bpe_tokenizer_pretrained.encode(data).tokens\n",
    "        \n",
    "        return token_rs\n",
    "    def WordPieceTokenizer(self, data : str) -> list:\n",
    "        \"\"\"\n",
    "        funcinfo WordPieceTokenizer: bert word piece로 훈련된 모델로 토큰화\n",
    "        param data : 토큰화할 문자 데이터\n",
    "        return token_rs: 토큰 결과\n",
    "        \"\"\"\n",
    "        token_rs = self.wp_tokenizer_pretrained.encode(data).tokens\n",
    "        \n",
    "        return token_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "572655f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data= \"\"\"우리 열차는 잠시 후 마지막 역인 서울역에 도착합니다. 미리 준비하시기 바랍니다.\n",
    "오늘도 빠르고 편안한 KTX를 이용해주신 고객 여러분, 고맙습니다. 안녕히 가십시오.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7b92394",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut_cls=UserTokenizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28da29c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['우리', '열차는', '잠시', '후', '마지막', '역인', '서울역에', '도착합니다.', '미리', '준비하시기', '바랍니다.\\n오늘도', '빠르고', '편안한', 'KTX를', '이용해주신', '고객', '여러분,', '고맙습니다.', '안녕히', '가십시오.\\n타는', '곳', '12번', '열차는,', '13시', '11분에', '서울로', '가는', 'KTX-산천', '411', '열차로,', '앞쪽에', '위치한', '11호차부터', '18호차까지', '이용해주시기', '바랍니다.\\n뒤쪽에', '위치한', '열차는', '13시', '11분에', '행신으로', '가는', 'KTX-산천', '413', '열차로,', '뒤쪽에', '위치한', '1호차부터', '8호차까지', '이용해주시기', '바랍니다.\\n이', '열차는', '두', '개의', '열차를', '하나로', '연결해', '운행하는', '열차로,', '8호차와', '11호차', '사이에는', '기관차가', '연결되어', '있어,', '객차', '사이를', '오갈수', '없습니다.\\n승차위치를', '다시', '한', '번', '확인해주시기', '바랍니다.', '열차', '곧', '출발하겠습니다.\\n']\n"
     ]
    }
   ],
   "source": [
    "print(ut_cls.whitespaceToken(sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a430299d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['우리 열차는 잠시 후 마지막 역인 서울역에 도착합니다', '미리 준비하시기 바랍니다', '오늘도 빠르고 편안한 KTX를 이용해주신 고객 여러분', '고맙습니다', '안녕히 가십시오', '타는 곳 12번 열차는', '13시 11분에 서울로 가는 KTX-산천 411 열차로', '앞쪽에 위치한 11호차부터 18호차까지 이용해주시기 바랍니다', '뒤쪽에 위치한 열차는 13시 11분에 행신으로 가는 KTX-산천 413 열차로', '뒤쪽에 위치한 1호차부터 8호차까지 이용해주시기 바랍니다', '이 열차는 두 개의 열차를 하나로 연결해 운행하는 열차로', '8호차와 11호차 사이에는 기관차가 연결되어 있어', '객차 사이를 오갈수 없습니다', '승차위치를 다시 한 번 확인해주시기 바랍니다', '열차 곧 출발하겠습니다']\n"
     ]
    }
   ],
   "source": [
    "print(ut_cls.regexsplitToken(sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f1b4616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['우리', '열차는', '잠시', '후', '마지막', '역인', '서울역에', '도착합니다', '미리', '준비하시기', '바랍니다', '오늘도', '빠르고', '편안한', 'KTX를', '이용해주신', '고객', '여러분', '고맙습니다', '안녕히', '가십시오', '타는', '곳', '12번', '열차는', '13시', '11분에', '서울로', '가는', 'KTX', '산천', '411', '열차로', '앞쪽에', '위치한', '11호차부터', '18호차까지', '이용해주시기', '바랍니다', '뒤쪽에', '위치한', '열차는', '13시', '11분에', '행신으로', '가는', 'KTX', '산천', '413', '열차로', '뒤쪽에', '위치한', '1호차부터', '8호차까지', '이용해주시기', '바랍니다', '이', '열차는', '두', '개의', '열차를', '하나로', '연결해', '운행하는', '열차로', '8호차와', '11호차', '사이에는', '기관차가', '연결되어', '있어', '객차', '사이를', '오갈수', '없습니다', '승차위치를', '다시', '한', '번', '확인해주시기', '바랍니다', '열차', '곧', '출발하겠습니다']\n"
     ]
    }
   ],
   "source": [
    "print(ut_cls.regexselectToken(sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efe6a3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['우리 열차는 잠시 후 마지막 역인 서울역에 도착합', '. 미리 준비하시기 바랍', '.\\n오늘도 빠르고 편안한 KTX를 이용해주신 고객 여러분, 고맙습', '. 안녕히 가십시오.\\n타는 곳 12번 열차는, 13시 11분에 서울로 가는 KTX-산천 411 열차로, 앞쪽에 위치한 11호차부터 18호차까지 이용해주시기 바랍', '.\\n뒤쪽에 위치한 열차는 13시 11분에 행신으로 가는 KTX-산천 413 열차로, 뒤쪽에 위치한 1호차부터 8호차까지 이용해주시기 바랍', '.\\n이 열차는 두 개의 열차를 하나로 연결해 운행하는 열차로, 8호차와 11호차 사이에는 기관차가 연결되어 있어, 객차 사이를 오갈수 없습', '.\\n승차위치를 다시 한 번 확인해주시기 바랍', '. 열차 곧 출발하겠습']\n"
     ]
    }
   ],
   "source": [
    "print(ut_cls.regexsplitToken(sample_data, pat='니다'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c36e3e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['우리</w>', '열', '차', '는</w>', '잠시</w>', '후</w>', '마지막</w>', '역', '인</w>', '서울', '역에</w>', '도', '착', '합니다</w>', '.</w>', '미', '리</w>', '준비', '하시', '기</w>', '바랍니다</w>', '.</w>', '오늘도</w>', '빠', '르고</w>', '편안', '한</w>', 'K', 'T', 'X', '를</w>', '이용', '해주', '신</w>', '고', '객</w>', '여러분</w>', ',</w>', '고맙습니다</w>', '.</w>', '안', '녕', '히</w>', '가', '십', '시오</w>', '.</w>']\n"
     ]
    }
   ],
   "source": [
    "print(ut_cls.BPETokenizer(sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "912fc085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['우리', '열', '##차', '##는', '잠시', '후', '마지막', '역', '##인', '서울', '##역', '##에', '도', '##착', '##합니다', '.', '미리', '준비', '##하시', '##기', '바랍니다', '.', '오늘', '##도', '빠', '##르고', '편안', '##한', 'K', '##T', '##X', '##를', '이용', '##해주', '##신', '고', '##객', '여러분', ',', '고맙습니다', '.', '안녕', '##히', '가', '##십', '##시오', '.']\n"
     ]
    }
   ],
   "source": [
    "print(ut_cls.WordPieceTokenizer(sample_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
