{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e7f96a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tokenizers import Tokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e7a8a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserTokenizers:\n",
    "    \"\"\"class info : 사용자의 필요에 맞게 다양한 토크나이저를 적용하는 모듈\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        self.bpe_tokenizer_pretrained= Tokenizer.from_file(\"./mode_data/bpe_tokenizer.json\")\n",
    "        self.wp_tokenizer_pretrained= Tokenizer.from_file(\"./mode_data/wp_tokenizer.josn\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def whitespaceToken( data: str)-> list:\n",
    "        \"\"\"\n",
    "        funcinfo whitespaceToken: 공백문자로 데이터를 나누는 토큰화\n",
    "        param data : 토큰화할 문자 데이터\n",
    "        return token_rs: 토큰 결과 \n",
    "        \"\"\"\n",
    "        token_rs= data.split(' ')\n",
    "        return token_rs\n",
    "    @staticmethod\n",
    "    def regexsplitToken(data: str, pat: str = '[\\.\\,!?\\n]')-> list:\n",
    "        \"\"\"\n",
    "        funcinfo regexsplitToken: 정규표현식의 패턴을 기준으로 데이터를 토큰화\n",
    "        param data : 토큰화할 문자 데이터\n",
    "        param pat : 토큰화할 정규식\n",
    "        return token_rs: 토큰 결과\n",
    "        \"\"\"\n",
    "        re_rs= re.split(pat, data, maxsplit=0)\n",
    "        token_rs=[rs_unit.strip()for rs_unit in re_rs if len(rs_unit.strip())>1]\n",
    "        return token_rs\n",
    "    @staticmethod\n",
    "    def regexselectToken(data: str, pat: str='[\\w]+') -> list:\n",
    "        \"\"\"\n",
    "        funcinfo regexselectToken: 정규표현식의 패턴을 선택하여 토큰화\n",
    "        param data : 토큰화할 문자 데이터\n",
    "        param pat : 토큰화할 정규식\n",
    "        return token_rs: 토큰 결과\n",
    "        \"\"\"\n",
    "        token_rs = RegexpTokenizer(pat).tokenize(data)\n",
    "        return token_rs\n",
    "    \n",
    "    def BPETokenizer(self, data : str) -> list :\n",
    "        \"\"\"\n",
    "        funcinfo BPETokenizer: char bpe로 훈련된 모델로 토큰화\n",
    "        param data : 토큰화할 문자 데이터\n",
    "        return token_rs: 토큰 결과\n",
    "        \"\"\"\n",
    "        token_rs = self.bpe_tokenizer_pretrained.encode(data).tokens\n",
    "        \n",
    "        return token_rs\n",
    "    def WordPieceTokenizer(self, data : str) -> list:\n",
    "        \"\"\"\n",
    "        funcinfo WordPieceTokenizer: bert word piece로 훈련된 모델로 토큰화\n",
    "        param data : 토큰화할 문자 데이터\n",
    "        return token_rs: 토큰 결과\n",
    "        \"\"\"\n",
    "        token_rs = self.wp_tokenizer_pretrained.encode(data).tokens\n",
    "        \n",
    "        return token_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a99b621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data= \"\"\"우리 열차는 잠시 후 마지막 역인 서울역에 도착합니다. 미리 준비하시기 바랍니다.\n",
    "오늘도 빠르고 편안한 KTX를 이용해주신 고객 여러분, 고맙습니다. 안녕히 가십시오.\n",
    "타는 곳 12번 열차는, 13시 11분에 서울로 가는 KTX-산천 411 열차로, 앞쪽에 위치한 11호차부터 18호차까지 이용해주시기 바랍니다.\n",
    "뒤쪽에 위치한 열차는 13시 11분에 행신으로 가는 KTX-산천 413 열차로, 뒤쪽에 위치한 1호차부터 8호차까지 이용해주시기 바랍니다.\n",
    "이 열차는 두 개의 열차를 하나로 연결해 운행하는 열차로, 8호차와 11호차 사이에는 기관차가 연결되어 있어, 객차 사이를 오갈수 없습니다. 승차위치를 다시 한 번 확인해주시기 바랍니다. 열차 곧 출발하겠습니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08eba15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut_cls=UserTokenizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df600821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['우리', '열차는', '잠시', '후', '마지막', '역인', '서울역에', '도착합니다.', '미리', '준비하시기', '바랍니다.\\n오늘도', '빠르고', '편안한', 'KTX를', '이용해주신', '고객', '여러분,', '고맙습니다.', '안녕히', '가십시오.\\n타는', '곳', '12번', '열차는,', '13시', '11분에', '서울로', '가는', 'KTX-산천', '411', '열차로,', '앞쪽에', '위치한', '11호차부터', '18호차까지', '이용해주시기', '바랍니다.\\n뒤쪽에', '위치한', '열차는', '13시', '11분에', '행신으로', '가는', 'KTX-산천', '413', '열차로,', '뒤쪽에', '위치한', '1호차부터', '8호차까지', '이용해주시기', '바랍니다.\\n이', '열차는', '두', '개의', '열차를', '하나로', '연결해', '운행하는', '열차로,', '8호차와', '11호차', '사이에는', '기관차가', '연결되어', '있어,', '객차', '사이를', '오갈수', '없습니다.\\n승차위치를', '다시', '한', '번', '확인해주시기', '바랍니다.', '열차', '곧', '출발하겠습니다.\\n']\n"
     ]
    }
   ],
   "source": [
    "print(ut_cls.whitespaceToken(sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49cc43d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['우리 열차는 잠시 후 마지막 역인 서울역에 도착합니다', '미리 준비하시기 바랍니다', '오늘도 빠르고 편안한 KTX를 이용해주신 고객 여러분', '고맙습니다', '안녕히 가십시오', '타는 곳 12번 열차는', '13시 11분에 서울로 가는 KTX-산천 411 열차로', '앞쪽에 위치한 11호차부터 18호차까지 이용해주시기 바랍니다', '뒤쪽에 위치한 열차는 13시 11분에 행신으로 가는 KTX-산천 413 열차로', '뒤쪽에 위치한 1호차부터 8호차까지 이용해주시기 바랍니다', '이 열차는 두 개의 열차를 하나로 연결해 운행하는 열차로', '8호차와 11호차 사이에는 기관차가 연결되어 있어', '객차 사이를 오갈수 없습니다', '승차위치를 다시 한 번 확인해주시기 바랍니다', '열차 곧 출발하겠습니다']\n"
     ]
    }
   ],
   "source": [
    "print(ut_cls.regexsplitToken(sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e39e7ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['우리', '열차는', '잠시', '후', '마지막', '역인', '서울역에', '도착합니다', '미리', '준비하시기', '바랍니다', '오늘도', '빠르고', '편안한', 'KTX를', '이용해주신', '고객', '여러분', '고맙습니다', '안녕히', '가십시오', '타는', '곳', '12번', '열차는', '13시', '11분에', '서울로', '가는', 'KTX', '산천', '411', '열차로', '앞쪽에', '위치한', '11호차부터', '18호차까지', '이용해주시기', '바랍니다', '뒤쪽에', '위치한', '열차는', '13시', '11분에', '행신으로', '가는', 'KTX', '산천', '413', '열차로', '뒤쪽에', '위치한', '1호차부터', '8호차까지', '이용해주시기', '바랍니다', '이', '열차는', '두', '개의', '열차를', '하나로', '연결해', '운행하는', '열차로', '8호차와', '11호차', '사이에는', '기관차가', '연결되어', '있어', '객차', '사이를', '오갈수', '없습니다', '승차위치를', '다시', '한', '번', '확인해주시기', '바랍니다', '열차', '곧', '출발하겠습니다']\n"
     ]
    }
   ],
   "source": [
    "print(ut_cls.regexselectToken(sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a10f288d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['우리 열차는 잠시 후 마지막 역인 서울역에 도착합', '. 미리 준비하시기 바랍', '.\\n오늘도 빠르고 편안한 KTX를 이용해주신 고객 여러분, 고맙습', '. 안녕히 가십시오.\\n타는 곳 12번 열차는, 13시 11분에 서울로 가는 KTX-산천 411 열차로, 앞쪽에 위치한 11호차부터 18호차까지 이용해주시기 바랍', '.\\n뒤쪽에 위치한 열차는 13시 11분에 행신으로 가는 KTX-산천 413 열차로, 뒤쪽에 위치한 1호차부터 8호차까지 이용해주시기 바랍', '.\\n이 열차는 두 개의 열차를 하나로 연결해 운행하는 열차로, 8호차와 11호차 사이에는 기관차가 연결되어 있어, 객차 사이를 오갈수 없습', '.\\n승차위치를 다시 한 번 확인해주시기 바랍', '. 열차 곧 출발하겠습']\n"
     ]
    }
   ],
   "source": [
    "print(ut_cls.regexsplitToken(sample_data, pat='니다'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8973b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['우리</w>', '열', '차', '는</w>', '잠시</w>', '후</w>', '마지막</w>', '역', '인</w>', '서울', '역에</w>', '도', '착', '합니다</w>', '.</w>', '미', '리</w>', '준비', '하시', '기</w>', '바랍니다</w>', '.</w>', '오늘도</w>', '빠', '르고</w>', '편안', '한</w>', 'K', 'T', 'X', '를</w>', '이용', '해주', '신</w>', '고', '객</w>', '여러분</w>', ',</w>', '고맙습니다</w>', '.</w>', '안', '녕', '히</w>', '가', '십', '시오</w>', '.</w>', '타는</w>', '곳</w>', '12', '번</w>', '열', '차', '는</w>', ',</w>', '13', '시</w>', '11', '분에</w>', '서울', '로</w>', '가는</w>', 'K', 'T', 'X</w>', '-</w>', '산', '천</w>', '4', '1', '1</w>', '열', '차', '로</w>', ',</w>', '앞', '쪽', '에</w>', '위', '치', '한</w>', '11', '호', '차', '부터</w>', '18', '호', '차', '까지</w>', '이용', '해주', '시', '기</w>', '바랍니다</w>', '.</w>', '뒤', '쪽', '에</w>', '위', '치', '한</w>', '열', '차', '는</w>', '13', '시</w>', '11', '분에</w>', '행', '신', '으로</w>', '가는</w>', 'K', 'T', 'X</w>', '-</w>', '산', '천</w>', '4', '1', '3</w>', '열', '차', '로</w>', ',</w>', '뒤', '쪽', '에</w>', '위', '치', '한</w>', '1', '호', '차', '부터</w>', '8', '호', '차', '까지</w>', '이용', '해주', '시', '기</w>', '바랍니다</w>', '.</w>', '이</w>', '열', '차', '는</w>', '두</w>', '개의</w>', '열', '차', '를</w>', '하나로</w>', '연결', '해</w>', '운', '행', '하는</w>', '열', '차', '로</w>', ',</w>', '8', '호', '차', '와</w>', '11', '호', '차</w>', '사이', '에는</w>', '기', '관', '차', '가</w>', '연결', '되어</w>', '있어</w>', ',</w>', '객', '차</w>', '사이', '를</w>', '오', '갈', '수</w>', '없습니다</w>', '.</w>', '승', '차', '위', '치를</w>', '다시</w>', '한</w>', '번</w>', '확인', '해주', '시', '기</w>', '바랍니다</w>', '.</w>', '열', '차</w>', '<unk>', '출', '발', '하겠습니다</w>', '.</w>']\n"
     ]
    }
   ],
   "source": [
    "print(ut_cls.BPETokenizer(sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa2fffba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['우리', '열', '##차', '##는', '잠시', '후', '마지막', '역', '##인', '서울', '##역', '##에', '도', '##착', '##합니다', '.', '미리', '준비', '##하시', '##기', '바랍니다', '.', '오늘', '##도', '빠', '##르고', '편안', '##한', 'K', '##T', '##X', '##를', '이용', '##해주', '##신', '고', '##객', '여러분', ',', '고맙습니다', '.', '안녕', '##히', '가', '##십', '##시오', '.', '타', '##는', '곳', '12', '##번', '열', '##차', '##는', ',', '13', '##시', '11', '##분에', '서울', '##로', '가는', 'K', '##T', '##X', '-', '산', '##천', '4', '##11', '열', '##차', '##로', ',', '앞', '##쪽', '##에', '위', '##치', '##한', '11', '##호', '##차', '##부터', '18', '##호', '##차', '##까지', '이용', '##해주', '##시기', '바랍니다', '.', '뒤', '##쪽', '##에', '위', '##치', '##한', '열', '##차', '##는', '13', '##시', '11', '##분에', '행', '##신', '##으로', '가는', 'K', '##T', '##X', '-', '산', '##천', '4', '##1', '##3', '열', '##차', '##로', ',', '뒤', '##쪽', '##에', '위', '##치', '##한', '1', '##호', '##차', '##부터', '8', '##호', '##차', '##까지', '이용', '##해주', '##시기', '바랍니다', '.', '이', '열', '##차', '##는', '두', '개', '##의', '열', '##차', '##를', '하나로', '연결', '##해', '운', '##행', '##하는', '열', '##차', '##로', ',', '8', '##호', '##차', '##와', '11', '##호', '##차', '사이', '##에는', '기', '##관', '##차', '##가', '연결', '##되어', '있어', ',', '객', '##차', '사이', '##를', '오', '##갈', '##수', '없습니다', '.', '승', '##차', '##위', '##치를', '다시', '한', '번', '확인', '##해주', '##시기', '바랍니다', '.', '열', '##차', '[UNK]', '출발', '##하겠습니다', '.']\n"
     ]
    }
   ],
   "source": [
    "print(ut_cls.WordPieceTokenizer(sample_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
